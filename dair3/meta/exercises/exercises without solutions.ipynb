{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Meta analysis exercises for DAIR3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats.distributions as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "**Background:** The function _gen_study_dat_ below simulates data from multiple independent two-arm studies.  We are able to specify the number of studies (n_study), the population effect size (pes), and some parameters that control how the per-arm sample sizes are generated (arm_size_mean, arm_size_cv, and arm_size_cor).  Finally, var_cv controls how the variances of the data in each study are simulated.  The average data variance is 1, but different studies have different variances and the [coefficient of variation](https://en.wikipedia.org/wiki/Coefficient_of_variation) of these variances is given by var_cv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_study_dat(n_study, pes, arm_size_mean, arm_size_cv, arm_size_cor, var_cv):\n",
    "    \"\"\"\n",
    "    Simulate data for meta-analysis.  Each study in the meta-analysis is a two arm-study/\n",
    "    The population effect sizes are identical (the population is homogeneous).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_study : number of studies\n",
    "    pes : population effect size (can be scalar for homogeneous or vector for heterogeneous studies)\n",
    "    arm_size_mean : the expected sample size of one study arm\n",
    "    arm_size_cv : the coefficient of variation of study arm sizes\n",
    "    arm_size_cor : the correlation between effect sizes of the two arms (on copula scale)\n",
    "    var_cv : the coeffient of variation of the unexplained variance\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    The unexplained variance always has mean 1.\n",
    "    \"\"\"\n",
    "    # Generate sample sizes for two arms in each study using a Gaussian copula\n",
    "    z = np.random.normal(size=(n_study, 2))\n",
    "    z[:, 1] = arm_size_cor*z[:, 0] + np.sqrt(1-arm_size_cor**2)*z[:, 1]\n",
    "    u = dist.norm.cdf(z)\n",
    "    v = (arm_size_mean * arm_size_cv)**2\n",
    "    a = arm_size_mean**2 / v\n",
    "    b = v / arm_size_mean\n",
    "    N = dist.gamma(a, scale=b).ppf(u)\n",
    "    N = np.ceil(N).astype(int)\n",
    "    N1 = N[:, 0]\n",
    "    N2 = N[:, 1]\n",
    "    \n",
    "    # Now generate variances, centered at 1\n",
    "    v = var_cv**2\n",
    "    sig = np.random.gamma(1/v, scale=v, size=n_study)\n",
    "    \n",
    "    f = (N1 + N2) / (N1 * N2)\n",
    "    se = np.sqrt(sig**2 * f)\n",
    "    md = pes + np.random.normal(size=n_study) * se\n",
    "    \n",
    "    return md, sig, N1, N2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cochrane_Q(md, se):\n",
    "    \"\"\"\n",
    "    Assess heterogeneity in a meta-analysis using Cochrane's approach.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    md : vector of point estimates (e.g. mean differences)\n",
    "    se : vector of standard errors\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    q : Cochrane's Q statistic\n",
    "    pval : A p-value testing the null hypothesis of no heterogeneity\n",
    "    I2 : The I2 statistic quantifying the extent of heterogeneity\n",
    "    \"\"\"\n",
    "    w = 1 / se**2\n",
    "    w /= w.sum()\n",
    "    pe = np.dot(md, w) # pooled estimate\n",
    "    q = np.sum((md - pe)**2 / se**2) # q-statistic\n",
    "    pval = 1 - dist.chi2(len(md) - 1).cdf(q)\n",
    "    I2 = 1 - (len(md) - 1) / q\n",
    "    return q, pval, I2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "md, sig, N1, N2 = gen_study_dat(20, 0.1, 30, 0.5, 0.7, 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "**Exercise 1:**\n",
    "\n",
    "The cell above generates data from 20 two-arm studies that are suitable for a meta-analysis.  The vectors _md_, _sig_, _N1_, and _N2_ contain, respectively, the estimated mean difference, estimated pooled standard deviation, arm 1 sample size, and arm 2 sample size.  All results pertain to a set of 30 studies estimating a common parameter of interest.\n",
    "\n",
    "Answer the following sequence of questions, which could arise in a meta-analysis using these data.\n",
    "\n",
    "a: Efficiently estimate the consensus effect size\n",
    "\n",
    "b: Estimate the standard error of the consensus effect size from part a\n",
    "\n",
    "c: Modify the study characteristics (the parameters in _gen_study_dat_) to identify a setting where we reject the null hypothesis of zero consensus effect around half of the time (review the documentation for the _gen_study_dat_ function above to understand what the parameters mean). \n",
    "\n",
    "d: In the scenario that you constructed in part c, around how many of the studies would have been considered to produce statistically significant evidence of an effect if considered in isolation?\n",
    "\n",
    "e: Configure the parameters for _gen_study_dat_ as you like, then calculate a p-value for each study (considered in isolation), and use Fisher's method to produce an overall p-value.  Try to find a setting where the p-value for Fisher's method is less than 0.05 around half of the time.\n",
    "\n",
    "f: Generate data using _gen_study_dat_ that has homogeneous effect sizes.  Calculate the Cochrane Q-statistic and confirm that the results are what you would expect.  Then generate data having heterogeneous effect sizes, and again check the results of the Cochrane Q-statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part f\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
